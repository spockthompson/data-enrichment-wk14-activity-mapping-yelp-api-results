{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d4c9a7",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "# Part 2 - Mapping Yelp Search Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be6e6c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1dfbbf",
   "metadata": {},
   "source": [
    "## Obective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37daea31",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "- For this CodeAlong, we will be working with the Yelp API results from last class. \n",
    "- You will load in the .csv.gz of your yelp results and prepare the data for visualization.\n",
    "- You will use Plotly Express to create an interactive map with all of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02a2fd",
   "metadata": {
    "id": "8guYh-VR7nlX"
   },
   "source": [
    "## Tools You Will Use\n",
    "- Part 1:\n",
    "    - Yelp API:\n",
    "        - Getting Started: \n",
    "            - https://www.yelp.com/developers/documentation/v3/get_started\n",
    "\n",
    "    - `YelpAPI` python package\n",
    "        -  \"YelpAPI\": https://github.com/gfairchild/yelpapi\n",
    "- Part 2:\n",
    "\n",
    "    - Plotly Express: https://plotly.com/python/getting-started/\n",
    "        - With Mapbox API: https://www.mapbox.com/\n",
    "        - `px.scatter_mapbox` [Documentation](https://plotly.com/python/scattermapbox/): \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f15049",
   "metadata": {},
   "source": [
    "### Applying Code From\n",
    "- [Advanced Transformations with Pandas - Part 1](https://login.codingdojo.com/m/376/12529/88086)\n",
    "- [Advanced Transformations with Pandas - Part 2](https://login.codingdojo.com/m/376/12529/88088)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e757f",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ea8f9",
   "metadata": {},
   "source": [
    "- We want to create a map with every restaurant plotted as a scatter plot with detailed information that appears when we hover over a business\n",
    "- We will use plotly express's `px.scatter_mapbox` function to accomplish this.\n",
    "    - https://plotly.com/python/scattermapbox/\n",
    "    \n",
    "    - We will need a Mapbox API token for some of the options:\n",
    "        - https://studio.mapbox.com/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50b2b6",
   "metadata": {},
   "source": [
    "# Loading Data from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa40ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in c:\\users\\scyjt\\coding_stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages (5.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\scyjt\\coding_stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages (from plotly) (8.1.0)\n"
     ]
    }
   ],
   "source": [
    "## Plotly is not included in your dojo-env\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c26b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "\n",
    "## importing plotly \n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f882e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## Load in csv.gz\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/Seattle-pizza.csv.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\Coding_Stuff\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "## Load in csv.gz\n",
    "df = pd.read_csv('Data/Seattle-pizza.csv.gz')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d9a50",
   "metadata": {},
   "source": [
    "## Required Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8a265",
   "metadata": {},
   "source": [
    "- 1. We need to get the latitude and longitude for each business as separate columns.\n",
    "- We also want to be able to show the restaurants:\n",
    "    - name,\n",
    "    - price range\n",
    "    - address\n",
    "    - and if they do delivery or takeout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d541ac",
   "metadata": {},
   "source": [
    "### Separating Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825c85f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## use .apply pd.Series to convert a dict to columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mSeries)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## use .apply pd.Series to convert a dict to columns\n",
    "df['coordinates'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecca22",
   "metadata": {},
   "source": [
    "- Why didn't that work???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out a single test coordinate\n",
    "test_coord = df.loc[1, 'coordinates']\n",
    "test_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d8252",
   "metadata": {},
   "source": [
    "- Its not a dictionary anymore!!! WTF??\n",
    "    - CSV files cant store iterables (lists, dictionaries) so they get converted to strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7e7c71",
   "metadata": {},
   "source": [
    "### Fixing the String-Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76185b76",
   "metadata": {},
   "source": [
    "- The json module has another version of load and dump called `json.loads` and `json.dumps`\n",
    "    - These are designed to process STRINGS instead of files. \n",
    "    \n",
    "- If we use `json.loads` we can convert our string dictionary into an actual dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ab9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use json.loads on the test coordinate\n",
    "json.loads(test_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89771042",
   "metadata": {},
   "source": [
    "- JSON requires double quotes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a459c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace single ' with \" \n",
    "test_coord =test_coord.replace(\"'\", '\"')\n",
    "test_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use json.loads on the test coordinate, again\n",
    "json.loads(test_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a2c61",
   "metadata": {},
   "source": [
    "### Now, how can we apply this same process to the entire column??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815d26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace ' with \" (entire column)\n",
    "df['coorinates']= df['coordinates'].str.replace(\"'\", '\"')\n",
    "## apply json.loads\n",
    "df['coorinates']= df['coorinates'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out a single test coordinate\n",
    "test_coord = df.loc[5,'coordinates']\n",
    "type(test_coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825c2f4",
   "metadata": {},
   "source": [
    "### Using Apply with pd.Series to convert a dictionary column into multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use .apply pd.Series to convert a dict to columns\n",
    "df['coordinates'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate the 2 new columns and drop the original.\n",
    "df = pd.concat([df,df['coordinates'].apply(pd.Series)],axis =1)\n",
    "df =df.drop(columns= 'coordinates')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b25f7a",
   "metadata": {},
   "source": [
    "## Creating a Simple Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5bc110",
   "metadata": {},
   "source": [
    "### Register for MapBox API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c91d8f",
   "metadata": {},
   "source": [
    "Mapbox API: https://www.mapbox.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in mapbox api credentials from .secret\n",
    "with open('/Users/scyjt/.secret/mapbox.json') as f:\n",
    "    login = json.load(f)\n",
    "login.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5689c",
   "metadata": {},
   "source": [
    "- Use the plotly express `set_maptbox_acccess_token` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set mapbox token\n",
    "px.set_mapbox_access_token(login['api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use scatter_mapbox for M.V.P map\n",
    "px.scatter_mapbox(df, lat= 'latitude',lon= 'logitude' ,mapbox_style='open-street-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b72ef0",
   "metadata": {},
   "source": [
    "### Adding Hover Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300eddca",
   "metadata": {},
   "source": [
    "- We want to show the restaurants:\n",
    "    - name\n",
    "    - price range\n",
    "    - address\n",
    "    - and if they do delivery or takeout.\n",
    "    \n",
    "    \n",
    "- We can use the `hover_name` and `hover_data` arguments for `px.scatter_mapbox` to add this info!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7ef9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e4e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## add hover_name (name) and hover_data for price,rating,location\n",
    "px.scatter_mapbox(df, lat= 'latitude',lon= 'logitude' ,mapbox_style='open-street-map' ,hover_name='name' ,\n",
    "                 hover_data= ['price','rating','location'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d744ca",
   "metadata": {},
   "source": [
    "### Fixing the Location Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out a test address\n",
    "test_addr =df.loc[0, 'location']\n",
    "test_addr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573de0f",
   "metadata": {},
   "source": [
    "> Also a string-dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5862a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replace ' with \"\n",
    "df['location'] = df['location'].str.replace(\"'\", '\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1606ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply json.loads\n",
    "df['location'] = df['location'].apply(json.loads)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3fc5c2",
   "metadata": {},
   "source": [
    "> Ruh roh....\n",
    "\n",
    "- Hmm, let's slice out a test_address again and let's write a function to accomplish this instead.\n",
    "    - We can use try and except in our function to get around the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe3a7a",
   "metadata": {},
   "source": [
    "### Fixing Addresses - with a custom function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1964520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out test address \n",
    "test_addr = df.loc[0, 'location']\n",
    "test_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write a function to just run json.loads on the address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test applying our function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbc436",
   "metadata": {},
   "source": [
    "- It worked! Now let's save this as a new column (display_location),\n",
    "and then let's investigate the businesses that had an \"ERROR\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a511e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save a new display_location column using our function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter for businesses with display_location == \"ERROR\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c115199",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out a new test address and inspect\n",
    "test_addr = df.loc[0, 'location']\n",
    "test_addr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fa8c6",
   "metadata": {},
   "source": [
    "> After some more investigation, we would find a few issues with these \"ERROR\" rows.\n",
    "1. They contained None.\n",
    "2. They contained an apostrophe in the name.\n",
    "3. ...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a960d4",
   "metadata": {},
   "source": [
    "### Possible Fixes (if we care to/have the time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21eda1",
   "metadata": {},
   "source": [
    "- Use Regular Expressions to find an fix the display addresses with \"'\" in them\n",
    "- Use string split to split on the word display address.\n",
    "    - Then use string methods to clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d68fb",
   "metadata": {},
   "source": [
    "### Moving Forward without those rows (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbcc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove any rows where display_location == 'ERROR'\n",
    "def fix_address(test_addr):\n",
    "    try:\n",
    "        return json.loads(test_addr)\n",
    "    except:\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].apply(fix_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c25a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['display_location'] = df['location'].apply(fix_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e812237",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = df[df['display_location']=='ERROR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aca3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_addr = df.loc[854, 'location']\n",
    "test_addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['display_location']!='Error']\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1338cd2",
   "metadata": {},
   "source": [
    "- We want the \"display_address\" key from the \"display_location\" dictionaries.\n",
    "- We could use a .apply and a lamda to slice out the desired key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82544b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use apply and lambda to slice correct key\n",
    "df['display_address'] = df['display_location'].apply(lambda x :x['display_address']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a79ab",
   "metadata": {},
   "source": [
    "- Almost done! We want to convert display_address to a string instead a list of strings.\n",
    "- We can use the string method .join to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice out a test_address\n",
    "test_add =df.loc[339, 'display_address']\n",
    "test_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876bb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test using .join with a \"\\n\"\n",
    "'\\n'.join(test_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a6176d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## apply the join to every row with a lambda\n",
    "df['Address'] = df['display_address'].apply(lambda x: '\\n'.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b90087",
   "metadata": {},
   "source": [
    "### Final Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make ourn final map and save as varaible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e93ee3",
   "metadata": {},
   "source": [
    "#### HTML Uses `<br>` instead of `\\n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2758626",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remake the final address column with <br> instead \n",
    "\n",
    "## plot the final map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e43699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use fig.write_html to save map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "299.195px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
